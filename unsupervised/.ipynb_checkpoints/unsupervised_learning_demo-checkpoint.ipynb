{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Demo: Understanding Hidden Patterns\n",
    "\n",
    "This notebook demonstrates key unsupervised learning concepts through interactive visualizations.\n",
    "\n",
    "## What is Unsupervised Learning?\n",
    "Unlike supervised learning, we don't have labeled data. Instead, we discover hidden patterns, structures, and relationships in data without knowing the \"correct\" answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs, load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: K-Means Clustering - Finding Hidden Groups\n",
    "\n",
    "Imagine you have customer data but don't know which customers belong to which segments. K-means helps discover these natural groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data (customer spending patterns)\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=1.5, random_state=42)\n",
    "\n",
    "# Visualize raw data\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.7, s=50)\n",
    "plt.title('Raw Data: Customer Spending\\n(No labels - what patterns exist?)')\n",
    "plt.xlabel('Annual Spending ($1000s)')\n",
    "plt.ylabel('Purchase Frequency')\n",
    "\n",
    "# Show K-means process\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i in range(4):\n",
    "    plt.scatter(X[clusters == i, 0], X[clusters == i, 1], \n",
    "               c=colors[i], alpha=0.7, s=50, label=f'Segment {i+1}')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', marker='x', s=200, linewidths=3)\n",
    "plt.title('K-Means Result\\n(Discovered 4 customer segments)')\n",
    "plt.xlabel('Annual Spending ($1000s)')\n",
    "plt.ylabel('Purchase Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show how to choose optimal K\n",
    "inertias = []\n",
    "K_range = range(1, 10)\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(K_range, inertias, 'bo-')\n",
    "plt.axvline(x=4, color='red', linestyle='--', alpha=0.7)\n",
    "plt.title('Elbow Method\\n(Optimal K = 4)')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç What K-Means Discovered:\")\n",
    "print(f\"‚Ä¢ Found {len(np.unique(clusters))} distinct customer segments\")\n",
    "print(f\"‚Ä¢ Each segment has different spending patterns\")\n",
    "print(f\"‚Ä¢ Black X marks show the center of each segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Principal Component Analysis (PCA) - Reducing Complexity\n",
    "\n",
    "Real datasets often have many features. PCA helps us understand which features matter most and visualize high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset (4 features: sepal length, sepal width, petal length, petal width)\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_iris)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Original 4D data (show first 2 dimensions)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], alpha=0.7)\n",
    "plt.title('Original Data\\n(4 dimensions - showing 2)')\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "\n",
    "# PCA visualization\n",
    "plt.subplot(1, 3, 2)\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(X_pca[y_iris == i, 0], X_pca[y_iris == i, 1], \n",
    "               c=color, alpha=0.7, label=iris.target_names[i])\n",
    "plt.title('After PCA\\n(2 dimensions capture most info)')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.legend()\n",
    "\n",
    "# Explained variance\n",
    "plt.subplot(1, 3, 3)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.bar(range(1, 5), pca.explained_variance_ratio_, alpha=0.7, label='Individual')\n",
    "plt.plot(range(1, 5), cumsum, 'ro-', label='Cumulative')\n",
    "plt.axhline(y=0.95, color='red', linestyle='--', alpha=0.7)\n",
    "plt.title('Variance Explained\\n(2 components = 95.8%)')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç What PCA Discovered:\")\n",
    "print(f\"‚Ä¢ Reduced 4 dimensions to 2 while keeping {cumsum[1]:.1%} of information\")\n",
    "print(f\"‚Ä¢ PC1 explains {pca.explained_variance_ratio_[0]:.1%} of variance\")\n",
    "print(f\"‚Ä¢ PC2 explains {pca.explained_variance_ratio_[1]:.1%} of variance\")\n",
    "print(f\"‚Ä¢ Clear separation between species becomes visible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: Interactive K-Means Animation\n",
    "\n",
    "Let's see how K-means algorithm actually works step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansAnimator:\n",
    "    def __init__(self, X, k=3):\n",
    "        self.X = X\n",
    "        self.k = k\n",
    "        self.n_samples = X.shape[0]\n",
    "        \n",
    "        # Initialize centroids randomly\n",
    "        self.centroids = X[np.random.choice(self.n_samples, k, replace=False)]\n",
    "        self.colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "        \n",
    "    def assign_clusters(self):\n",
    "        distances = np.sqrt(((self.X - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        return np.argmin(distances, axis=0)\n",
    "    \n",
    "    def update_centroids(self, clusters):\n",
    "        new_centroids = np.array([self.X[clusters == i].mean(axis=0) for i in range(self.k)])\n",
    "        return new_centroids\n",
    "    \n",
    "    def plot_step(self, step):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        if step == 0:\n",
    "            plt.scatter(self.X[:, 0], self.X[:, 1], c='gray', alpha=0.6, s=50)\n",
    "            plt.scatter(self.centroids[:, 0], self.centroids[:, 1], \n",
    "                       c=self.colors[:self.k], marker='x', s=200, linewidths=3)\n",
    "            plt.title('Step 0: Random Initial Centroids')\n",
    "        else:\n",
    "            clusters = self.assign_clusters()\n",
    "            \n",
    "            for i in range(self.k):\n",
    "                plt.scatter(self.X[clusters == i, 0], self.X[clusters == i, 1], \n",
    "                           c=self.colors[i], alpha=0.6, s=50)\n",
    "            \n",
    "            plt.scatter(self.centroids[:, 0], self.centroids[:, 1], \n",
    "                       c='black', marker='x', s=200, linewidths=3)\n",
    "            \n",
    "            plt.title(f'Step {step}: Assign Points & Update Centroids')\n",
    "            \n",
    "            # Update centroids for next iteration\n",
    "            self.centroids = self.update_centroids(clusters)\n",
    "        \n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# Generate data and show animation steps\n",
    "X_demo, _ = make_blobs(n_samples=150, centers=3, cluster_std=1.2, random_state=42)\n",
    "animator = KMeansAnimator(X_demo, k=3)\n",
    "\n",
    "print(\"üé¨ K-Means Algorithm Steps:\")\n",
    "print(\"\\n1. Start with random centroids\")\n",
    "animator.plot_step(0)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    print(f\"\\n{i+1}. Assign points to nearest centroid & update centroid positions\")\n",
    "    animator.plot_step(i)\n",
    "\n",
    "print(\"\\n‚úÖ Algorithm converged! Centroids stop moving significantly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: Real-World Application - Customer Segmentation\n",
    "\n",
    "Let's apply unsupervised learning to a realistic business scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic customer data\n",
    "np.random.seed(42)\n",
    "n_customers = 500\n",
    "\n",
    "# Generate customer features\n",
    "customer_data = {\n",
    "    'annual_spending': np.random.normal(5000, 2000, n_customers),\n",
    "    'visit_frequency': np.random.poisson(12, n_customers),\n",
    "    'avg_order_value': np.random.normal(150, 50, n_customers),\n",
    "    'days_since_last_purchase': np.random.exponential(30, n_customers)\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(customer_data)\n",
    "df = df[df['annual_spending'] > 0]  # Remove negative spending\n",
    "df = df[df['avg_order_value'] > 0]  # Remove negative order values\n",
    "\n",
    "print(\"üìä Customer Dataset Overview:\")\n",
    "print(df.describe().round(2))\n",
    "\n",
    "# Standardize features for clustering\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Apply K-means\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "df['segment'] = clusters\n",
    "\n",
    "# Visualize segments\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Spending vs Frequency\n",
    "plt.subplot(2, 3, 1)\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i in range(4):\n",
    "    mask = df['segment'] == i\n",
    "    plt.scatter(df[mask]['annual_spending'], df[mask]['visit_frequency'], \n",
    "               c=colors[i], alpha=0.6, label=f'Segment {i}')\n",
    "plt.xlabel('Annual Spending ($)')\n",
    "plt.ylabel('Visit Frequency')\n",
    "plt.title('Customer Segments')\n",
    "plt.legend()\n",
    "\n",
    "# Plot 2: Order Value vs Days Since Last Purchase\n",
    "plt.subplot(2, 3, 2)\n",
    "for i in range(4):\n",
    "    mask = df['segment'] == i\n",
    "    plt.scatter(df[mask]['avg_order_value'], df[mask]['days_since_last_purchase'], \n",
    "               c=colors[i], alpha=0.6, label=f'Segment {i}')\n",
    "plt.xlabel('Average Order Value ($)')\n",
    "plt.ylabel('Days Since Last Purchase')\n",
    "plt.title('Purchase Behavior')\n",
    "plt.legend()\n",
    "\n",
    "# Plot 3-6: Segment characteristics\n",
    "features = ['annual_spending', 'visit_frequency', 'avg_order_value', 'days_since_last_purchase']\n",
    "for idx, feature in enumerate(features):\n",
    "    plt.subplot(2, 3, idx + 3)\n",
    "    df.boxplot(column=feature, by='segment', ax=plt.gca())\n",
    "    plt.title(f'{feature.replace(\"_\", \" \").title()} by Segment')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze segments\n",
    "print(\"\\nüéØ Customer Segment Analysis:\")\n",
    "segment_analysis = df.groupby('segment').agg({\n",
    "    'annual_spending': 'mean',\n",
    "    'visit_frequency': 'mean', \n",
    "    'avg_order_value': 'mean',\n",
    "    'days_since_last_purchase': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_names = ['Budget Shoppers', 'VIP Customers', 'Regular Customers', 'At-Risk Customers']\n",
    "segment_analysis.index = segment_names\n",
    "print(segment_analysis)\n",
    "\n",
    "print(\"\\nüí° Business Insights:\")\n",
    "print(\"‚Ä¢ VIP Customers: High spending, frequent visits - focus on retention\")\n",
    "print(\"‚Ä¢ Regular Customers: Moderate activity - upselling opportunities\")\n",
    "print(\"‚Ä¢ Budget Shoppers: Price-sensitive - discount campaigns\")\n",
    "print(\"‚Ä¢ At-Risk Customers: Long time since purchase - re-engagement needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: When to Use Unsupervised Learning\n",
    "\n",
    "### ‚úÖ Use Unsupervised Learning When:\n",
    "- You don't have labeled data\n",
    "- You want to discover hidden patterns\n",
    "- You need to reduce data complexity\n",
    "- You want to segment customers/users\n",
    "- You're doing exploratory data analysis\n",
    "\n",
    "### üîß Common Applications:\n",
    "- **Clustering**: Customer segmentation, market research, gene sequencing\n",
    "- **Dimensionality Reduction**: Data visualization, feature selection, compression\n",
    "- **Anomaly Detection**: Fraud detection, quality control, network security\n",
    "\n",
    "### ‚ö†Ô∏è Challenges:\n",
    "- No \"ground truth\" to validate results\n",
    "- Choosing the right number of clusters\n",
    "- Interpreting results requires domain knowledge\n",
    "- Results can be sensitive to data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Exercise\n",
    "\n",
    "Try modifying the parameters below to see how they affect clustering results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive parameters - modify these!\n",
    "n_clusters = 3  # Try changing this: 2, 3, 4, 5\n",
    "n_samples = 200  # Try: 100, 200, 500\n",
    "cluster_std = 1.5  # Try: 0.5, 1.0, 2.0, 3.0\n",
    "\n",
    "# Generate new data\n",
    "X_interactive, _ = make_blobs(n_samples=n_samples, centers=n_clusters, \n",
    "                             cluster_std=cluster_std, random_state=42)\n",
    "\n",
    "# Apply clustering\n",
    "kmeans_interactive = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "clusters_interactive = kmeans_interactive.fit_predict(X_interactive)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_interactive[:, 0], X_interactive[:, 1], alpha=0.7)\n",
    "plt.title('Raw Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, n_clusters))\n",
    "for i in range(n_clusters):\n",
    "    plt.scatter(X_interactive[clusters_interactive == i, 0], \n",
    "               X_interactive[clusters_interactive == i, 1], \n",
    "               c=[colors[i]], alpha=0.7, label=f'Cluster {i+1}')\n",
    "plt.scatter(kmeans_interactive.cluster_centers_[:, 0], \n",
    "           kmeans_interactive.cluster_centers_[:, 1], \n",
    "           c='black', marker='x', s=200, linewidths=3)\n",
    "plt.title(f'K-Means Result (K={n_clusters})')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üéõÔ∏è Current settings: {n_clusters} clusters, {n_samples} samples, std={cluster_std}\")\n",
    "print(\"üí° Try changing the parameters above and re-run this cell!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
