{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Architecture in LLMs: Step-by-Step Demo\n",
    "\n",
    "This notebook demonstrates how encoder architectures work in Large Language Models, their significance, and provides interactive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is an Encoder?\n",
    "\n",
    "An encoder transforms input sequences into rich representations that capture semantic meaning. In LLMs:\n",
    "- **Input**: Raw text tokens\n",
    "- **Output**: Dense vector representations (embeddings)\n",
    "- **Purpose**: Create contextual understanding of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Encoder Layer Implementation\n",
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=8, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Self-attention with residual connection\n",
    "        attn_out, attn_weights = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        ff_out = self.linear2(F.relu(self.linear1(x)))\n",
    "        x = self.norm2(x + ff_out)\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "print(\"âœ“ Simple Encoder Layer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Step-by-Step Encoding Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenization\n",
    "sample_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.encode(sample_text, return_tensors='pt')\n",
    "\n",
    "print(f\"Original text: {sample_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs shape: {token_ids.shape}\")\n",
    "print(f\"Token IDs: {token_ids.squeeze().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Embedding Layer\n",
    "vocab_size = 30522  # BERT vocab size\n",
    "d_model = 512\n",
    "embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "# Convert tokens to embeddings\n",
    "token_embeddings = embedding(token_ids)\n",
    "print(f\"Token embeddings shape: {token_embeddings.shape}\")\n",
    "print(f\"Each token is now a {d_model}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Positional Encoding\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    pos = torch.arange(seq_len).unsqueeze(1).float()\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                        -(np.log(10000.0) / d_model))\n",
    "    \n",
    "    pe = torch.zeros(seq_len, d_model)\n",
    "    pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "    pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "    return pe.unsqueeze(0)\n",
    "\n",
    "seq_len = token_embeddings.size(1)\n",
    "pos_encoding = positional_encoding(seq_len, d_model)\n",
    "input_embeddings = token_embeddings + pos_encoding\n",
    "\n",
    "print(f\"Added positional encoding\")\n",
    "print(f\"Final input embeddings shape: {input_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoder Processing & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process through encoder\n",
    "encoder = SimpleEncoder(d_model=d_model)\n",
    "encoded_output, attention_weights = encoder(input_embeddings)\n",
    "\n",
    "print(f\"Encoded output shape: {encoded_output.shape}\")\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention patterns\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Multi-Head Attention Patterns', fontsize=16)\n",
    "\n",
    "# Show first 8 attention heads\n",
    "for i in range(8):\n",
    "    row, col = i // 4, i % 4\n",
    "    attn_matrix = attention_weights[0, i].detach().numpy()\n",
    "    \n",
    "    im = axes[row, col].imshow(attn_matrix, cmap='Blues')\n",
    "    axes[row, col].set_title(f'Head {i+1}')\n",
    "    axes[row, col].set_xlabel('Key Position')\n",
    "    axes[row, col].set_ylabel('Query Position')\n",
    "    \n",
    "    # Add token labels\n",
    "    if len(tokens) <= 10:  # Only for short sequences\n",
    "        axes[row, col].set_xticks(range(len(tokens)))\n",
    "        axes[row, col].set_yticks(range(len(tokens)))\n",
    "        axes[row, col].set_xticklabels(tokens, rotation=45)\n",
    "        axes[row, col].set_yticklabels(tokens)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-World Example with Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT encoder\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Process multiple sentences\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A dog ran in the park\", \n",
    "    \"Birds fly in the sky\",\n",
    "    \"Fish swim in the ocean\"\n",
    "]\n",
    "\n",
    "# Encode sentences\n",
    "encoded_sentences = []\n",
    "for sentence in sentences:\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use [CLS] token representation\n",
    "        sentence_embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        encoded_sentences.append(sentence_embedding.flatten())\n",
    "\n",
    "encoded_sentences = np.array(encoded_sentences)\n",
    "print(f\"Encoded {len(sentences)} sentences\")\n",
    "print(f\"Each sentence encoded as {encoded_sentences.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentence embeddings in 2D\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(encoded_sentences)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for i, (sentence, color) in enumerate(zip(sentences, colors)):\n",
    "    plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], \n",
    "               c=color, s=100, alpha=0.7)\n",
    "    plt.annotate(sentence, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "plt.title('Sentence Embeddings in 2D Space\\n(Similar meanings should cluster together)')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Significance of Encoders in LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate semantic similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Calculate similarities between sentences\n",
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        similarity_matrix[i, j] = cosine_similarity(encoded_sentences[i], encoded_sentences[j])\n",
    "\n",
    "# Visualize similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            xticklabels=[f\"S{i+1}\" for i in range(len(sentences))],\n",
    "            yticklabels=[f\"S{i+1}\" for i in range(len(sentences))])\n",
    "plt.title('Semantic Similarity Matrix\\n(Higher values = more similar meanings)')\n",
    "\n",
    "# Add sentence labels\n",
    "for i, sentence in enumerate(sentences):\n",
    "    plt.text(len(sentences) + 0.5, i + 0.5, f\"S{i+1}: {sentence}\", \n",
    "             va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Insights & Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate layer-wise representations\n",
    "def get_layer_representations(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    # Get [CLS] token representation from each layer\n",
    "    layer_reps = []\n",
    "    for layer_output in hidden_states:\n",
    "        cls_rep = layer_output[:, 0, :].numpy().flatten()\n",
    "        layer_reps.append(cls_rep)\n",
    "    \n",
    "    return np.array(layer_reps)\n",
    "\n",
    "# Analyze how representations change through layers\n",
    "test_sentence = \"The quick brown fox jumps\"\n",
    "layer_representations = get_layer_representations(test_sentence, model, tokenizer)\n",
    "\n",
    "print(f\"Sentence: '{test_sentence}'\")\n",
    "print(f\"Representations through {len(layer_representations)} layers\")\n",
    "print(f\"Each layer output: {layer_representations.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how representations evolve through layers\n",
    "layer_norms = [np.linalg.norm(rep) for rep in layer_representations]\n",
    "layer_changes = [np.linalg.norm(layer_representations[i] - layer_representations[i-1]) \n",
    "                for i in range(1, len(layer_representations))]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot representation magnitude through layers\n",
    "ax1.plot(range(len(layer_norms)), layer_norms, 'bo-')\n",
    "ax1.set_xlabel('Layer')\n",
    "ax1.set_ylabel('Representation Magnitude')\n",
    "ax1.set_title('How Representation Magnitude Changes\\nThrough Encoder Layers')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot layer-to-layer changes\n",
    "ax2.plot(range(1, len(layer_representations)), layer_changes, 'ro-')\n",
    "ax2.set_xlabel('Layer Transition')\n",
    "ax2.set_ylabel('Change Magnitude')\n",
    "ax2.set_title('Layer-to-Layer Representation Changes\\n(Higher = More Transformation)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Why Encoders Matter in LLMs\n",
    "\n",
    "**Key Functions:**\n",
    "1. **Contextual Understanding**: Transform tokens into context-aware representations\n",
    "2. **Semantic Capture**: Encode meaning, not just syntax\n",
    "3. **Hierarchical Processing**: Build increasingly abstract representations through layers\n",
    "4. **Attention Mechanisms**: Focus on relevant parts of input\n",
    "\n",
    "**Applications:**\n",
    "- Text classification\n",
    "- Semantic search\n",
    "- Question answering\n",
    "- Language understanding tasks\n",
    "\n",
    "**Architecture Benefits:**\n",
    "- Parallel processing (vs sequential RNNs)\n",
    "- Long-range dependencies\n",
    "- Transfer learning capabilities\n",
    "- Scalable to large contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ‰ Encoder Architecture Demo Complete!\")\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"â€¢ Encoders transform text into meaningful vector representations\")\n",
    "print(\"â€¢ Self-attention allows models to focus on relevant context\")\n",
    "print(\"â€¢ Multiple layers build increasingly abstract representations\")\n",
    "print(\"â€¢ Pre-trained encoders capture rich semantic knowledge\")\n",
    "print(\"â€¢ These representations enable various downstream NLP tasks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
