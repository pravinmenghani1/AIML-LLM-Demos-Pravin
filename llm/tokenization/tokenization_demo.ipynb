{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization in Large Language Models: A Complete Guide\n",
    "\n",
    "## Problem Statement\n",
    "Understanding how text is converted into numerical representations that LLMs can process is crucial for:\n",
    "- Optimizing prompt engineering\n",
    "- Managing token limits and costs\n",
    "- Understanding model behavior and limitations\n",
    "- Building efficient text processing pipelines\n",
    "\n",
    "This notebook demonstrates different tokenization methods, their trade-offs, and practical implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Tokenization?\n",
    "\n",
    "Tokenization is the process of breaking down text into smaller units (tokens) that can be processed by machine learning models. In LLMs, tokens are the basic units of input and output.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Token**: A unit of text (word, subword, or character)\n",
    "- **Vocabulary**: Set of all possible tokens the model knows\n",
    "- **Token ID**: Numerical representation of each token\n",
    "- **Out-of-Vocabulary (OOV)**: Tokens not in the model's vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2025.9.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (997 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.9.1-cp313-cp313-macosx_11_0_arm64.whl (286 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tiktoken]\n",
      "\u001b[1A\u001b[2KSuccessfully installed regex-2025.9.1 tiktoken-0.11.0\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from requests->transformers) (2025.6.15)\n",
      "Using cached transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: tqdm, safetensors, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.9 huggingface-hub-0.34.4 safetensors-0.6.2 tokenizers-0.22.0 tqdm-4.67.1 transformers-4.56.1\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.4.4/libexec/lib/python3.13/site-packages (2.3.2)\n",
      "\n",
      "*** IMPORTANT: Please restart the kernel (Kernel -> Restart) and then run the next cell ***\n"
     ]
    }
   ],
   "source": [
    "# Install required packages - RESTART KERNEL after running this cell\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['tiktoken', 'transformers', 'matplotlib', 'numpy']\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "print(\"\\n*** IMPORTANT: Please restart the kernel (Kernel -> Restart) and then run the next cell ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries (run this AFTER restarting kernel)\n",
    "import re\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Tokenization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Hello world! This is a demonstration of tokenization in LLMs. It's fascinating how models understand text.\n",
      "Text length: 106 characters\n"
     ]
    }
   ],
   "source": [
    "# Sample text for demonstration\n",
    "sample_text = \"Hello world! This is a demonstration of tokenization in LLMs. It's fascinating how models understand text.\"\n",
    "\n",
    "print(f\"Original text: {sample_text}\")\n",
    "print(f\"Text length: {len(sample_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Word-Level Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokens: ['hello', 'world', '!', 'this', 'is', 'a', 'demonstration', 'of', 'tokenization', 'in', 'llms', '.', 'it', \"'\", 's', 'fascinating', 'how', 'models', 'understand', 'text', '.']\n",
      "Number of tokens: 21\n"
     ]
    }
   ],
   "source": [
    "def word_tokenize(text):\n",
    "    # Simple word tokenization using regex\n",
    "    tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', text.lower())\n",
    "    return tokens\n",
    "\n",
    "word_tokens = word_tokenize(sample_text)\n",
    "print(f\"Word tokens: {word_tokens}\")\n",
    "print(f\"Number of tokens: {len(word_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Character-Level Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character tokens: ['H', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd', '!', ' ', 'T', 'h', 'i', 's', ' ', 'i', 's']...\n",
      "Number of tokens: 106\n"
     ]
    }
   ],
   "source": [
    "def char_tokenize(text):\n",
    "    return list(text)\n",
    "\n",
    "char_tokens = char_tokenize(sample_text)\n",
    "print(f\"Character tokens: {char_tokens[:20]}...\")  # Show first 20\n",
    "print(f\"Number of tokens: {len(char_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modern Tokenization: Byte Pair Encoding (BPE)\n",
    "\n",
    "BPE is a subword tokenization method that balances vocabulary size with meaningful representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple BPE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE tokens: ['hello', 'world']\n",
      "Learned merges: [('i', 's'), ('l', 'e'), ('p', 'le'), ('m', 'ple'), ('e', 'l')]...\n"
     ]
    }
   ],
   "source": [
    "class SimpleBPE:\n",
    "    def __init__(self, vocab_size=1000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab = {}\n",
    "        self.merges = {}\n",
    "    \n",
    "    def get_pairs(self, word):\n",
    "        pairs = set()\n",
    "        prev_char = word[0]\n",
    "        for char in word[1:]:\n",
    "            pairs.add((prev_char, char))\n",
    "            prev_char = char\n",
    "        return pairs\n",
    "    \n",
    "    def train(self, corpus):\n",
    "        # Initialize vocabulary with characters\n",
    "        vocab = set()\n",
    "        word_freqs = Counter(corpus.split())\n",
    "        \n",
    "        # Convert words to character sequences\n",
    "        word_splits = {}\n",
    "        for word in word_freqs:\n",
    "            word_splits[word] = list(word)\n",
    "            vocab.update(word_splits[word])\n",
    "        \n",
    "        # Learn merges\n",
    "        num_merges = self.vocab_size - len(vocab)\n",
    "        \n",
    "        for i in range(num_merges):\n",
    "            pairs = {}\n",
    "            for word, freq in word_freqs.items():\n",
    "                word_pairs = self.get_pairs(word_splits[word])\n",
    "                for pair in word_pairs:\n",
    "                    pairs[pair] = pairs.get(pair, 0) + freq\n",
    "            \n",
    "            if not pairs:\n",
    "                break\n",
    "                \n",
    "            best_pair = max(pairs, key=pairs.get)\n",
    "            self.merges[best_pair] = len(vocab)\n",
    "            vocab.add(''.join(best_pair))\n",
    "            \n",
    "            # Update word splits\n",
    "            for word in word_splits:\n",
    "                new_word = []\n",
    "                i = 0\n",
    "                while i < len(word_splits[word]):\n",
    "                    if (i < len(word_splits[word]) - 1 and \n",
    "                        (word_splits[word][i], word_splits[word][i+1]) == best_pair):\n",
    "                        new_word.append(''.join(best_pair))\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        new_word.append(word_splits[word][i])\n",
    "                        i += 1\n",
    "                word_splits[word] = new_word\n",
    "        \n",
    "        self.vocab = {token: i for i, token in enumerate(vocab)}\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        tokens = []\n",
    "        for word in text.split():\n",
    "            word_tokens = list(word)\n",
    "            \n",
    "            # Apply learned merges\n",
    "            for pair in self.merges:\n",
    "                new_tokens = []\n",
    "                i = 0\n",
    "                while i < len(word_tokens):\n",
    "                    if (i < len(word_tokens) - 1 and \n",
    "                        (word_tokens[i], word_tokens[i+1]) == pair):\n",
    "                        new_tokens.append(''.join(pair))\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        new_tokens.append(word_tokens[i])\n",
    "                        i += 1\n",
    "                word_tokens = new_tokens\n",
    "            \n",
    "            tokens.extend(word_tokens)\n",
    "        return tokens\n",
    "\n",
    "# Train simple BPE\n",
    "corpus = \"hello world this is a simple example of tokenization\"\n",
    "bpe = SimpleBPE(vocab_size=50)\n",
    "bpe.train(corpus)\n",
    "\n",
    "bpe_tokens = bpe.tokenize(\"hello world\")\n",
    "print(f\"BPE tokens: {bpe_tokens}\")\n",
    "print(f\"Learned merges: {list(bpe.merges.keys())[:5]}...\")  # Show first 5 merges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-World Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 OpenAI's tiktoken (GPT models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 tokens: [9906, 1917, 0, 1115, 374, 264, 30816, 315, 4037, 2065, 304, 445, 11237, 82, 13, 1102, 596, 27387, 1268, 4211, 3619, 1495, 13]\n",
      "GPT-4 decoded: ['Hello', ' world', '!', ' This', ' is', ' a', ' demonstration', ' of', ' token', 'ization', ' in', ' L', 'LM', 's', '.', ' It', \"'s\", ' fascinating', ' how', ' models', ' understand', ' text', '.']\n",
      "Number of tokens: 23\n"
     ]
    }
   ],
   "source": [
    "# GPT-4 tokenizer\n",
    "gpt4_tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "gpt4_tokens = gpt4_tokenizer.encode(sample_text)\n",
    "gpt4_decoded = [gpt4_tokenizer.decode([token]) for token in gpt4_tokens]\n",
    "\n",
    "print(f\"GPT-4 tokens: {gpt4_tokens}\")\n",
    "print(f\"GPT-4 decoded: {gpt4_decoded}\")\n",
    "print(f\"Number of tokens: {len(gpt4_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hugging Face Transformers (BERT, GPT-2, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5d83f48b7f4c5c9353b97e03dc07c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44d3501548445c3a916efb2c8e20123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfebfdaaedff498a915ff85726a1fe8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea53432186cb484cb40952ee346c237c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT tokens: ['hello', 'world', '!', 'this', 'is', 'a', 'demonstration', 'of', 'token', '##ization', 'in', 'll', '##ms', '.', 'it', \"'\", 's', 'fascinating', 'how', 'models', 'understand', 'text', '.']\n",
      "BERT token IDs: [101, 7592, 2088, 999, 2023, 2003, 1037, 10467, 1997, 19204, 3989, 1999, 2222, 5244, 1012, 2009, 1005, 1055, 17160, 2129, 4275, 3305, 3793, 1012, 102]\n",
      "Number of tokens: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46795fef0144230b9fcddc88ef0948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e87c6529dbe4e7982622e4ff3d0dac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedd36f7b3c94abca9db2490a2045b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242782a289ba4664bbb4e82f83651f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000c11ce45b74b4d91b7b30256b6d801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 tokens: ['Hello', 'Ġworld', '!', 'ĠThis', 'Ġis', 'Ġa', 'Ġdemonstration', 'Ġof', 'Ġtoken', 'ization', 'Ġin', 'ĠLL', 'Ms', '.', 'ĠIt', \"'s\", 'Ġfascinating', 'Ġhow', 'Ġmodels', 'Ġunderstand', 'Ġtext', '.']\n",
      "Number of tokens: 22\n"
     ]
    }
   ],
   "source": [
    "# BERT tokenizer\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_tokens = bert_tokenizer.tokenize(sample_text)\n",
    "bert_ids = bert_tokenizer.encode(sample_text)\n",
    "\n",
    "print(f\"BERT tokens: {bert_tokens}\")\n",
    "print(f\"BERT token IDs: {bert_ids}\")\n",
    "print(f\"Number of tokens: {len(bert_tokens)}\")\n",
    "\n",
    "# GPT-2 tokenizer\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "gpt2_tokens = gpt2_tokenizer.tokenize(sample_text)\n",
    "\n",
    "print(f\"\\nGPT-2 tokens: {gpt2_tokens}\")\n",
    "print(f\"Number of tokens: {len(gpt2_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenization Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                                               Word   Char   GPT-4  BERT   GPT-2 \n",
      "--------------------------------------------------------------------------------\n",
      "Hello world!                                       3      12     3      3      3     \n",
      "Tokenization is fascinating.                       4      28     5      5      5     \n",
      "The quick brown fox jumps over the lazy dog.       10     44     10     10     10    \n",
      "AI and machine learning are revolutionizing technology. 8      55     9      9      9     \n",
      "Supercalifragilisticexpialidocious                 1      34     11     11     11    \n"
     ]
    }
   ],
   "source": [
    "# Compare different tokenization methods\n",
    "test_texts = [\n",
    "    \"Hello world!\",\n",
    "    \"Tokenization is fascinating.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"AI and machine learning are revolutionizing technology.\",\n",
    "    \"Supercalifragilisticexpialidocious\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for text in test_texts:\n",
    "    word_count = len(word_tokenize(text))\n",
    "    char_count = len(char_tokenize(text))\n",
    "    gpt4_count = len(gpt4_tokenizer.encode(text))\n",
    "    bert_count = len(bert_tokenizer.tokenize(text))\n",
    "    gpt2_count = len(gpt2_tokenizer.tokenize(text))\n",
    "    \n",
    "    results.append({\n",
    "        'text': text,\n",
    "        'word': word_count,\n",
    "        'char': char_count,\n",
    "        'gpt4': gpt4_count,\n",
    "        'bert': bert_count,\n",
    "        'gpt2': gpt2_count\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(f\"{'Text':<50} {'Word':<6} {'Char':<6} {'GPT-4':<6} {'BERT':<6} {'GPT-2':<6}\")\n",
    "print(\"-\" * 80)\n",
    "for result in results:\n",
    "    print(f\"{result['text']:<50} {result['word']:<6} {result['char']:<6} {result['gpt4']:<6} {result['bert']:<6} {result['gpt2']:<6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Tokenization Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualization\n",
    "methods = ['Word', 'Character', 'GPT-4', 'BERT', 'GPT-2']\n",
    "text_labels = [f\"Text {i+1}\" for i in range(len(test_texts))]\n",
    "\n",
    "word_counts = [r['word'] for r in results]\n",
    "char_counts = [r['char'] for r in results]\n",
    "gpt4_counts = [r['gpt4'] for r in results]\n",
    "bert_counts = [r['bert'] for r in results]\n",
    "gpt2_counts = [r['gpt2'] for r in results]\n",
    "\n",
    "x = np.arange(len(text_labels))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(x - 2*width, word_counts, width, label='Word', alpha=0.8)\n",
    "ax.bar(x - width, char_counts, width, label='Character', alpha=0.8)\n",
    "ax.bar(x, gpt4_counts, width, label='GPT-4', alpha=0.8)\n",
    "ax.bar(x + width, bert_counts, width, label='BERT', alpha=0.8)\n",
    "ax.bar(x + 2*width, gpt2_counts, width, label='GPT-2', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Test Texts')\n",
    "ax.set_ylabel('Number of Tokens')\n",
    "ax.set_title('Tokenization Comparison Across Different Methods')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(text_labels)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Special Tokens and Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens and edge cases:\n",
      "Text: Hello! How are you? I'm fine. 😊 Check out https://example.com\n",
      "\n",
      "GPT-4 tokens: ['Hello', '!', ' How', ' are', ' you', '?', ' I', \"'m\", ' fine', '.', ' �', '�', ' Check', ' out', ' https', '://', 'example', '.com']\n",
      "BERT tokens: ['hello', '!', 'how', 'are', 'you', '?', 'i', \"'\", 'm', 'fine', '.', '[UNK]', 'check', 'out', 'https', ':', '/', '/', 'example', '.', 'com']\n",
      "BERT with special tokens: ['[CLS]', 'hello', '!', 'how', 'are', 'you', '?', 'i', \"'\", 'm', 'fine', '.', '[UNK]', 'check', 'out', 'https', ':', '/', '/', 'example', '.', 'com', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate special tokens\n",
    "special_text = \"Hello! How are you? I'm fine. 😊 Check out https://example.com\"\n",
    "\n",
    "print(\"Special tokens and edge cases:\")\n",
    "print(f\"Text: {special_text}\")\n",
    "print()\n",
    "\n",
    "# GPT-4 handling\n",
    "gpt4_special = gpt4_tokenizer.encode(special_text)\n",
    "gpt4_decoded_special = [gpt4_tokenizer.decode([token]) for token in gpt4_special]\n",
    "print(f\"GPT-4 tokens: {gpt4_decoded_special}\")\n",
    "\n",
    "# BERT handling\n",
    "bert_special = bert_tokenizer.tokenize(special_text)\n",
    "print(f\"BERT tokens: {bert_special}\")\n",
    "\n",
    "# Show special tokens in BERT\n",
    "bert_with_special = bert_tokenizer.encode(special_text, add_special_tokens=True)\n",
    "bert_decoded_with_special = bert_tokenizer.convert_ids_to_tokens(bert_with_special)\n",
    "print(f\"BERT with special tokens: {bert_decoded_with_special}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Practical Implications for LLM Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Analysis for Sample Prompt:\n",
      "Token count: 100\n",
      "Input cost: $0.0030\n",
      "Estimated total cost: $0.0060\n"
     ]
    }
   ],
   "source": [
    "# Token counting for cost estimation\n",
    "def estimate_cost(text, model=\"gpt-4\", input_cost_per_1k=0.03, output_cost_per_1k=0.06):\n",
    "    \"\"\"Estimate API cost based on token count\"\"\"\n",
    "    if model == \"gpt-4\":\n",
    "        tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    else:\n",
    "        tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    \n",
    "    token_count = len(tokenizer.encode(text))\n",
    "    input_cost = (token_count / 1000) * input_cost_per_1k\n",
    "    \n",
    "    return {\n",
    "        'tokens': token_count,\n",
    "        'input_cost': input_cost,\n",
    "        'estimated_output_tokens': token_count * 0.5,  # Rough estimate\n",
    "        'estimated_total_cost': input_cost + ((token_count * 0.5) / 1000) * output_cost_per_1k\n",
    "    }\n",
    "\n",
    "# Example prompt\n",
    "long_prompt = \"\"\"\n",
    "You are an AI assistant helping with data analysis. \n",
    "Please analyze the following dataset and provide insights:\n",
    "\n",
    "Dataset: Sales data for Q1 2024\n",
    "- January: $50,000 revenue, 200 customers\n",
    "- February: $65,000 revenue, 250 customers  \n",
    "- March: $80,000 revenue, 320 customers\n",
    "\n",
    "Please provide:\n",
    "1. Growth rate analysis\n",
    "2. Customer acquisition trends\n",
    "3. Revenue per customer metrics\n",
    "4. Recommendations for Q2\n",
    "\"\"\"\n",
    "\n",
    "cost_analysis = estimate_cost(long_prompt)\n",
    "print(\"Cost Analysis for Sample Prompt:\")\n",
    "print(f\"Token count: {cost_analysis['tokens']}\")\n",
    "print(f\"Input cost: ${cost_analysis['input_cost']:.4f}\")\n",
    "print(f\"Estimated total cost: ${cost_analysis['estimated_total_cost']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices and Optimization Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Optimization Example:\n",
      "Verbose prompt: 48 tokens\n",
      "Optimized prompt: 9 tokens\n",
      "Token reduction: 39 tokens (81.2% reduction)\n",
      "\n",
      "Best Practices:\n",
      "1. Use concise language\n",
      "2. Avoid redundant phrases\n",
      "3. Use bullet points instead of long sentences\n",
      "4. Remove unnecessary politeness markers\n",
      "5. Use abbreviations where appropriate\n",
      "6. Structure data efficiently (JSON vs prose)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate token optimization techniques\n",
    "verbose_prompt = \"\"\"\n",
    "I would like you to please help me with analyzing this data. \n",
    "Could you please take a look at the following information and \n",
    "provide me with some insights? I would really appreciate it if \n",
    "you could give me a detailed analysis.\n",
    "\"\"\"\n",
    "\n",
    "optimized_prompt = \"\"\"\n",
    "Analyze this data and provide insights:\n",
    "\"\"\"\n",
    "\n",
    "verbose_tokens = len(gpt4_tokenizer.encode(verbose_prompt))\n",
    "optimized_tokens = len(gpt4_tokenizer.encode(optimized_prompt))\n",
    "\n",
    "print(\"Prompt Optimization Example:\")\n",
    "print(f\"Verbose prompt: {verbose_tokens} tokens\")\n",
    "print(f\"Optimized prompt: {optimized_tokens} tokens\")\n",
    "print(f\"Token reduction: {verbose_tokens - optimized_tokens} tokens ({((verbose_tokens - optimized_tokens) / verbose_tokens * 100):.1f}% reduction)\")\n",
    "\n",
    "print(\"\\nBest Practices:\")\n",
    "print(\"1. Use concise language\")\n",
    "print(\"2. Avoid redundant phrases\")\n",
    "print(\"3. Use bullet points instead of long sentences\")\n",
    "print(\"4. Remove unnecessary politeness markers\")\n",
    "print(\"5. Use abbreviations where appropriate\")\n",
    "print(\"6. Structure data efficiently (JSON vs prose)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Token Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Text: AI is amazing!\n",
      "Character count: 14\n",
      "\n",
      "Word tokens: 4\n",
      "GPT-4 tokens: 4\n",
      "BERT tokens: 4\n",
      "\n",
      "GPT-4 tokenization: ['AI', ' is', ' amazing', '!']\n",
      "BERT tokenization: ['ai', 'is', 'amazing', '!']\n",
      "\n",
      "============================================================\n",
      "Text: The quick brown fox jumps over the lazy dog.\n",
      "Character count: 44\n",
      "\n",
      "Word tokens: 10\n",
      "GPT-4 tokens: 10\n",
      "BERT tokens: 10\n",
      "\n",
      "GPT-4 tokenization: ['The', ' quick', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy', ' dog', '.']\n",
      "BERT tokenization: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "\n",
      "============================================================\n",
      "Text: Antidisestablishmentarianism\n",
      "Character count: 28\n",
      "\n",
      "Word tokens: 1\n",
      "GPT-4 tokens: 6\n",
      "BERT tokens: 8\n",
      "\n",
      "GPT-4 tokenization: ['Ant', 'idis', 'establish', 'ment', 'arian', 'ism']\n",
      "BERT tokenization: ['anti', '##dis', '##est', '##ab', '##lish', '##ment', '##arian', '##ism']\n",
      "\n",
      "============================================================\n",
      "Text: 🚀 Rocket to the moon! 🌙\n",
      "Character count: 23\n",
      "\n",
      "Word tokens: 7\n",
      "GPT-4 tokens: 11\n",
      "BERT tokens: 7\n",
      "\n",
      "GPT-4 tokenization: ['�', '�', '�', ' Rocket', ' to', ' the', ' moon', '!', ' �', '�', '�']\n",
      "BERT tokenization: ['[UNK]', 'rocket', 'to', 'the', 'moon', '!', '[UNK]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def interactive_token_counter(text):\n",
    "    \"\"\"Interactive function to analyze any text\"\"\"\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Character count: {len(text)}\")\n",
    "    print()\n",
    "    \n",
    "    # Different tokenization methods\n",
    "    word_tokens = word_tokenize(text)\n",
    "    gpt4_tokens = gpt4_tokenizer.encode(text)\n",
    "    bert_tokens = bert_tokenizer.tokenize(text)\n",
    "    \n",
    "    print(f\"Word tokens: {len(word_tokens)}\")\n",
    "    print(f\"GPT-4 tokens: {len(gpt4_tokens)}\")\n",
    "    print(f\"BERT tokens: {len(bert_tokens)}\")\n",
    "    print()\n",
    "    \n",
    "    # Show actual tokens\n",
    "    gpt4_decoded = [gpt4_tokenizer.decode([token]) for token in gpt4_tokens]\n",
    "    print(f\"GPT-4 tokenization: {gpt4_decoded}\")\n",
    "    print(f\"BERT tokenization: {bert_tokens}\")\n",
    "    \n",
    "    return {\n",
    "        'word_count': len(word_tokens),\n",
    "        'gpt4_count': len(gpt4_tokens),\n",
    "        'bert_count': len(bert_tokens)\n",
    "    }\n",
    "\n",
    "# Test with different examples\n",
    "test_cases = [\n",
    "    \"AI is amazing!\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Antidisestablishmentarianism\",\n",
    "    \"🚀 Rocket to the moon! 🌙\"\n",
    "]\n",
    "\n",
    "for test_text in test_cases:\n",
    "    print(\"=\" * 60)\n",
    "    interactive_token_counter(test_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Tokenization Methods**:\n",
    "   - Word-level: Simple but large vocabulary\n",
    "   - Character-level: Small vocabulary but long sequences\n",
    "   - Subword (BPE): Balanced approach used by modern LLMs\n",
    "\n",
    "2. **Modern Tokenizers**:\n",
    "   - GPT models use tiktoken with BPE\n",
    "   - BERT uses WordPiece tokenization\n",
    "   - Each has different vocabulary and token counts\n",
    "\n",
    "3. **Practical Implications**:\n",
    "   - Token count affects API costs\n",
    "   - Different models tokenize differently\n",
    "   - Optimization can reduce costs significantly\n",
    "\n",
    "4. **Best Practices**:\n",
    "   - Monitor token usage for cost control\n",
    "   - Optimize prompts for efficiency\n",
    "   - Understand model-specific tokenization\n",
    "   - Consider special tokens and edge cases\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with your own text\n",
    "- Try different models and compare tokenization\n",
    "- Implement token counting in your applications\n",
    "- Optimize prompts for better efficiency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
